{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kilroy-module-huggingface \ud83d\udd17 kilroy module using Hugging Face models \ud83e\udd17 Installing \ud83d\udd17 Using pip : pip install kilroy-module-huggingface Usage \ud83d\udd17 To run the module server, install the package and run the following command: kilroy-module-huggingface This will start the face server on port 11000 by default. Then you can communicate with the server, for example by using this package .","title":"Home"},{"location":"#kilroy-module-huggingface","text":"kilroy module using Hugging Face models \ud83e\udd17","title":"kilroy-module-huggingface"},{"location":"#installing","text":"Using pip : pip install kilroy-module-huggingface","title":"Installing"},{"location":"#usage","text":"To run the module server, install the package and run the following command: kilroy-module-huggingface This will start the face server on port 11000 by default. Then you can communicate with the server, for example by using this package .","title":"Usage"},{"location":"usage/","text":"Usage \ud83d\udd17 This package provides an interface to any HuggingFace model that complies with the kilroy module API. Prerequisites \ud83d\udd17 By default, the module uses the gpt2 model. If you want to use another model, you need to pick a sufficiently powerful one for text generation. You can find a list of models here . Also make sure that you have enough memory to load the model. Running the server \ud83d\udd17 To run the module server, install the package and run the following command: kilroy-module-huggingface This will start the face server on port 11000 by default. Then you can communicate with the server, for example by using this package .","title":"Usage"},{"location":"usage/#usage","text":"This package provides an interface to any HuggingFace model that complies with the kilroy module API.","title":"Usage"},{"location":"usage/#prerequisites","text":"By default, the module uses the gpt2 model. If you want to use another model, you need to pick a sufficiently powerful one for text generation. You can find a list of models here . Also make sure that you have enough memory to load the model.","title":"Prerequisites"},{"location":"usage/#running-the-server","text":"To run the module server, install the package and run the following command: kilroy-module-huggingface This will start the face server on port 11000 by default. Then you can communicate with the server, for example by using this package .","title":"Running the server"}]}